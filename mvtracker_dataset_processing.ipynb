{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### load data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "scene = \"football\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np \n",
    "\n",
    "point_tracks = np.load(f\"/restricted/projectnb/cs599dg/mwakeham/datasets/panoptic-multiview/{scene}/tapvid3d_annotations.npz\")\n",
    "\n",
    "print(list(point_tracks.keys()))\n",
    "print(point_tracks['trajectories'].shape)\n",
    "print(point_tracks['trajectories_pixelspace'].shape)\n",
    "print(point_tracks['per_view_visibilities'].shape)\n",
    "print(point_tracks['intrinsics'].shape)\n",
    "print(point_tracks['extrinsics'].shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### get examples\n",
    "\n",
    "sample 4 views\n",
    "\n",
    "sample 200 3D point tracks\n",
    "\n",
    "keep the 100 with most visibility across the views"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "np.random.seed(1234)\n",
    "\n",
    "visibilities = point_tracks['per_view_visibilities']\n",
    "pixel_trajectories = point_tracks['trajectories_pixelspace']\n",
    "\n",
    "# basketball scene\n",
    "num_repeats = 100\n",
    "num_views = 1\n",
    "num_candidate_points = 2000\n",
    "num_keep_points = 2000\n",
    "min_frames_per_view = 0\n",
    "max_attempts = 1000000\n",
    "\n",
    "# # boxes scene\n",
    "# num_repeats = 100\n",
    "# num_views = 4\n",
    "# num_candidate_points = 500\n",
    "# num_keep_points = 100\n",
    "# min_frames_per_view = 130\n",
    "# max_attempts = 1000000\n",
    "\n",
    "# # football scene\n",
    "# num_repeats = 100\n",
    "# num_views = 4\n",
    "# num_candidate_points = 500\n",
    "# num_keep_points = 100\n",
    "# min_frames_per_view = 115\n",
    "# max_attempts = 1000000\n",
    "\n",
    "# # juggle scene\n",
    "# num_repeats = 100\n",
    "# num_views = 4\n",
    "# num_candidate_points = 500\n",
    "# num_keep_points = 100\n",
    "# min_frames_per_view = 100\n",
    "# max_attempts = 1000000\n",
    "\n",
    "# # softball scene\n",
    "# num_repeats = 100\n",
    "# num_views = 4\n",
    "# num_candidate_points = 500\n",
    "# num_keep_points = 100\n",
    "# min_frames_per_view = 90\n",
    "# max_attempts = 1000000\n",
    "\n",
    "# # tennis scene\n",
    "# num_repeats = 100\n",
    "# num_views = 4\n",
    "# num_candidate_points = 500\n",
    "# num_keep_points = 100\n",
    "# min_frames_per_view = 100\n",
    "# max_attempts = 1000000\n",
    "\n",
    "all_candidate_vis_counts = []\n",
    "all_selected_vis_counts = []\n",
    "\n",
    "all_examples = []\n",
    "attempts = 0\n",
    "\n",
    "while len(all_examples) < num_repeats and attempts < max_attempts:\n",
    "    attempts += 1\n",
    "    \n",
    "    selected_views = np.random.choice(visibilities.shape[0], size=num_views, replace=False)\n",
    "    \n",
    "    candidate_points = np.random.choice(visibilities.shape[2], size=num_candidate_points, replace=False)\n",
    "    \n",
    "    vis = visibilities[selected_views][:, :, candidate_points]\n",
    "    \n",
    "    frames_visible_per_view = (vis >= 1).sum(axis=1)\n",
    "    \n",
    "    valid_points_mask = np.all(frames_visible_per_view >= min_frames_per_view, axis=0)\n",
    "    valid_candidate_points = candidate_points[valid_points_mask]\n",
    "    \n",
    "    if len(valid_candidate_points) < num_keep_points:\n",
    "        continue\n",
    "    \n",
    "    total_vis = vis[:, :, valid_points_mask].sum(axis=0).sum(axis=0)\n",
    "    top_points_idx = np.argsort(-total_vis)[:num_keep_points]\n",
    "    selected_points = valid_candidate_points[top_points_idx]\n",
    "    \n",
    "    all_candidate_vis_counts.extend(vis.sum(axis=0).sum(axis=0))\n",
    "\n",
    "    selected_mask = np.isin(candidate_points, selected_points)\n",
    "    all_selected_vis_counts.extend(vis[:, :, selected_mask].sum(axis=0).sum(axis=0))\n",
    "    \n",
    "    traj_pixel = pixel_trajectories[selected_views][:, :, selected_points, :]\n",
    "    \n",
    "    all_examples.append({\n",
    "        'views': selected_views,\n",
    "        'points': selected_points,\n",
    "        'trajectories_pixel': traj_pixel\n",
    "    })\n",
    "    \n",
    "    if len(all_examples) % 10 == 0:\n",
    "        print(f\"Collected {len(all_examples)}/{num_repeats} examples (attempt {attempts})\")\n",
    "\n",
    "if all_examples:\n",
    "    avg_vis_candidates = np.mean(all_candidate_vis_counts)\n",
    "    sd_vis_candidates = np.std(all_candidate_vis_counts)\n",
    "    avg_vis_selected = np.mean(all_selected_vis_counts)\n",
    "    sd_vis_selected = np.std(all_selected_vis_counts)\n",
    "\n",
    "    print(f\"\\nSuccessfully collected {len(all_examples)} examples\")\n",
    "    print(f\"Success rate: {len(all_examples)/attempts*100:.1f}%\")\n",
    "    print(f\"Candidate points visibility: avg={avg_vis_candidates:.2f}, sd={sd_vis_candidates:.2f}\")\n",
    "    print(f\"Selected points visibility: avg={avg_vis_selected:.2f}, sd={sd_vis_selected:.2f}\")\n",
    "else:\n",
    "    print(\"No examples met the criteria! You may need to relax min_frames_per_view\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### save visualization videos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import subprocess\n",
    "import cv2\n",
    "import numpy as np\n",
    "import tempfile\n",
    "\n",
    "base_path = f\"/restricted/projectnb/cs599dg/mwakeham/datasets/panoptic-multiview/{scene}/ims\"\n",
    "\n",
    "i = 99 # example number\n",
    "example = all_examples[i]\n",
    "views_to_convert = example['views']\n",
    "trajectories_pixel = example['trajectories_pixel']\n",
    "\n",
    "visibilities = point_tracks['per_view_visibilities']\n",
    "selected_points = example['points']\n",
    "selected_views = example['views']\n",
    "\n",
    "point_visibilities = visibilities[selected_views][:, :, selected_points]\n",
    "\n",
    "print(f\"Converting views: {views_to_convert}\")\n",
    "\n",
    "fade_frames = 10\n",
    "color2 = (180, 105, 255)\n",
    "\n",
    "for view_idx, view in enumerate(views_to_convert):\n",
    "    image_folder = os.path.join(base_path, str(view))\n",
    "    output_dir = f\"examples_visualization/{scene}/example{i}\"\n",
    "    os.makedirs(output_dir, exist_ok=True)\n",
    "    \n",
    "    import glob\n",
    "    image_files = sorted(glob.glob(os.path.join(image_folder, \"*.jpg\")))\n",
    "    \n",
    "    if not image_files:\n",
    "        print(f\"No images found in {image_folder}\")\n",
    "        continue\n",
    "    \n",
    "    with tempfile.TemporaryDirectory() as temp_dir_original, \\\n",
    "         tempfile.TemporaryDirectory() as temp_dir_overlay, \\\n",
    "         tempfile.TemporaryDirectory() as temp_dir_tracks_only:\n",
    "        \n",
    "        print(f\"Processing view {view}...\")\n",
    "        \n",
    "        view_trajectories = trajectories_pixel[view_idx]\n",
    "        view_visibilities = point_visibilities[view_idx]\n",
    "        num_frames = len(view_trajectories)\n",
    "        \n",
    "        for frame_idx, image_path in enumerate(image_files):\n",
    "            if frame_idx >= num_frames:\n",
    "                break\n",
    "                \n",
    "            img = cv2.imread(image_path)\n",
    "            if img is None:\n",
    "                continue\n",
    "            \n",
    "            original_frame_path = os.path.join(temp_dir_original, f\"frame_{frame_idx:06d}.jpg\")\n",
    "            cv2.imwrite(original_frame_path, img)\n",
    "            \n",
    "            img_with_overlay = img.copy()\n",
    "            \n",
    "            tracks_only = np.zeros_like(img)\n",
    "            \n",
    "            for point_idx in range(len(view_trajectories[frame_idx])):\n",
    "                if view_visibilities[frame_idx, point_idx] < 1:\n",
    "                    continue\n",
    "                \n",
    "                current_x, current_y = view_trajectories[frame_idx, point_idx]\n",
    "                if np.isnan(current_x) or np.isnan(current_y):\n",
    "                    continue\n",
    "                \n",
    "                current_x_int, current_y_int = int(round(current_x)), int(round(current_y))\n",
    "                \n",
    "                start_frame = max(0, frame_idx - fade_frames)\n",
    "                \n",
    "                for hist_frame in range(start_frame, frame_idx):\n",
    "                    if (view_visibilities[hist_frame, point_idx] < 1 or \n",
    "                        view_visibilities[hist_frame + 1, point_idx] < 1):\n",
    "                        continue\n",
    "                    \n",
    "                    fade_idx = frame_idx - hist_frame - 1\n",
    "                    if fade_idx >= fade_frames:\n",
    "                        continue\n",
    "                    \n",
    "                    ratio = fade_idx / fade_frames\n",
    "                    b = int(255 + (180 - 255) * ratio)\n",
    "                    g = int(0 + (105 - 0) * ratio)\n",
    "                    r = int(255 + (255 - 255) * ratio)\n",
    "                    color = (b, g, r)\n",
    "                    \n",
    "                    hist_x, hist_y = view_trajectories[hist_frame, point_idx]\n",
    "                    next_x, next_y = view_trajectories[hist_frame + 1, point_idx]\n",
    "                    \n",
    "                    if (not np.isnan(hist_x) and not np.isnan(hist_y) and \n",
    "                        not np.isnan(next_x) and not np.isnan(next_y)):\n",
    "                        \n",
    "                        hist_x_int, hist_y_int = int(round(hist_x)), int(round(hist_y))\n",
    "                        next_x_int, next_y_int = int(round(next_x)), int(round(next_y))\n",
    "                        \n",
    "                        cv2.line(img_with_overlay, (hist_x_int, hist_y_int), (next_x_int, next_y_int), color, 1)\n",
    "                        cv2.line(tracks_only, (hist_x_int, hist_y_int), (next_x_int, next_y_int), color, 1)\n",
    "                \n",
    "                cv2.circle(img_with_overlay, (current_x_int, current_y_int), 1, color2, -1)\n",
    "                cv2.circle(tracks_only, (current_x_int, current_y_int), 1, color2, -1)\n",
    "            \n",
    "            overlay_frame_path = os.path.join(temp_dir_overlay, f\"frame_{frame_idx:06d}.jpg\")\n",
    "            cv2.imwrite(overlay_frame_path, img_with_overlay)\n",
    "            \n",
    "            tracks_frame_path = os.path.join(temp_dir_tracks_only, f\"frame_{frame_idx:06d}.jpg\")\n",
    "            cv2.imwrite(tracks_frame_path, tracks_only)\n",
    "        \n",
    "        # Original video\n",
    "        original_output = os.path.join(output_dir, f\"view{view}.mp4\")\n",
    "        cmd_original = [\n",
    "            'ffmpeg', \n",
    "            '-framerate', '30',\n",
    "            '-i', os.path.join(temp_dir_original, 'frame_%06d.jpg'),\n",
    "            '-c:v', 'libx264',\n",
    "            '-pix_fmt', 'yuv420p',\n",
    "            original_output,\n",
    "            '-y'\n",
    "        ]\n",
    "        \n",
    "        # Video with tracks overlay\n",
    "        overlay_output = os.path.join(output_dir, f\"view{view}_with_tracks.mp4\")\n",
    "        cmd_overlay = [\n",
    "            'ffmpeg', \n",
    "            '-framerate', '30',\n",
    "            '-i', os.path.join(temp_dir_overlay, 'frame_%06d.jpg'),\n",
    "            '-c:v', 'libx264',\n",
    "            '-pix_fmt', 'yuv420p',\n",
    "            overlay_output,\n",
    "            '-y'\n",
    "        ]\n",
    "        \n",
    "        # Tracks only on black background\n",
    "        tracks_output = os.path.join(output_dir, f\"tracks{view}.mp4\")\n",
    "        cmd_tracks = [\n",
    "            'ffmpeg', \n",
    "            '-framerate', '30',\n",
    "            '-i', os.path.join(temp_dir_tracks_only, 'frame_%06d.jpg'),\n",
    "            '-c:v', 'libx264',\n",
    "            '-pix_fmt', 'yuv420p',\n",
    "            tracks_output,\n",
    "            '-y'\n",
    "        ]\n",
    "        \n",
    "        for cmd, output_path, name in [\n",
    "            (cmd_original, original_output, \"original\"),\n",
    "            (cmd_overlay, overlay_output, \"with tracks\"),\n",
    "            (cmd_tracks, tracks_output, \"tracks only\")\n",
    "        ]:\n",
    "            result = subprocess.run(cmd, capture_output=True, text=True)\n",
    "            if result.returncode == 0:\n",
    "                print(f\"{name} video saved to: {output_path}\")\n",
    "            else:\n",
    "                print(f\"Failed to create {name} video for view {view}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tqdm import tqdm\n",
    "import os\n",
    "import subprocess\n",
    "import cv2\n",
    "import numpy as np\n",
    "import tempfile\n",
    "import glob\n",
    "\n",
    "base_path = f\"/restricted/projectnb/cs599dg/mwakeham/datasets/panoptic-multiview/{scene}/ims\"\n",
    "\n",
    "i = 99 # example number\n",
    "example = all_examples[i]\n",
    "views_to_convert = example['views']\n",
    "trajectories_pixel = example['trajectories_pixel'] \n",
    "\n",
    "visibilities = point_tracks['per_view_visibilities']\n",
    "selected_points = example['points']\n",
    "selected_views = example['views']\n",
    "\n",
    "point_visibilities = visibilities[selected_views][:, :, selected_points]\n",
    "\n",
    "print(f\"Converting views: {views_to_convert}\")\n",
    "\n",
    "fade_frames = 10\n",
    "pink = (255, 0, 255)\n",
    "blue = (248, 252, 3)\n",
    "\n",
    "num_total_points = trajectories_pixel.shape[2]\n",
    "pink_points_count = int(2 * num_total_points / 3)\n",
    "point_colors = ['pink'] * pink_points_count + ['blue'] * (num_total_points - pink_points_count)\n",
    "\n",
    "print(f\"Total points: {num_total_points}, Pink: {pink_points_count}, Blue: {num_total_points - pink_points_count}\")\n",
    "\n",
    "# Pre-compute color gradients for faster access\n",
    "pink_gradients = []\n",
    "blue_gradients = []\n",
    "for fade_idx in range(fade_frames):\n",
    "    ratio = fade_idx / fade_frames\n",
    "    # Pink gradient\n",
    "    b = int(255 + (180 - 255) * ratio)\n",
    "    g = int(0 + (105 - 0) * ratio)\n",
    "    r = int(255 + (255 - 255) * ratio)\n",
    "    pink_gradients.append((b, g, r))\n",
    "    \n",
    "    # Blue gradient  \n",
    "    b = int(255 + (180 - 255) * ratio)\n",
    "    g = int(0 + (0 - 0) * ratio)\n",
    "    r = int(0 + (0 - 0) * ratio)\n",
    "    blue_gradients.append((b, g, r))\n",
    "\n",
    "for view_idx, view in enumerate(views_to_convert):\n",
    "    image_folder = os.path.join(base_path, str(view))\n",
    "    output_dir = f\"examples_visualization/{scene}/example{i}\"\n",
    "    os.makedirs(output_dir, exist_ok=True)\n",
    "    \n",
    "    image_files = sorted(glob.glob(os.path.join(image_folder, \"*.jpg\")))\n",
    "    if not image_files:\n",
    "        print(f\"No images found in {image_folder}\")\n",
    "        continue\n",
    "    \n",
    "    # Create temporary directories\n",
    "    with tempfile.TemporaryDirectory() as temp_dir_original, \\\n",
    "         tempfile.TemporaryDirectory() as temp_dir_overlay, \\\n",
    "         tempfile.TemporaryDirectory() as temp_dir_tracks_only, \\\n",
    "         tempfile.TemporaryDirectory() as temp_dir_pink_overlay, \\\n",
    "         tempfile.TemporaryDirectory() as temp_dir_blue_overlay, \\\n",
    "         tempfile.TemporaryDirectory() as temp_dir_pink_only, \\\n",
    "         tempfile.TemporaryDirectory() as temp_dir_blue_only:\n",
    "        \n",
    "        view_trajectories = trajectories_pixel[view_idx]\n",
    "        view_visibilities = point_visibilities[view_idx]\n",
    "        num_frames = min(len(view_trajectories), len(image_files))\n",
    "        \n",
    "        images = []\n",
    "        for frame_idx, image_path in enumerate(image_files):\n",
    "            if frame_idx >= num_frames:\n",
    "                break\n",
    "            img = cv2.imread(image_path)\n",
    "            images.append(img)\n",
    "        \n",
    "        if not images:\n",
    "            continue\n",
    "            \n",
    "        for frame_idx in tqdm(range(num_frames)):\n",
    "            if frame_idx >= len(images):\n",
    "                break\n",
    "                \n",
    "            img = images[frame_idx]\n",
    "            \n",
    "            cv2.imwrite(os.path.join(temp_dir_original, f\"frame_{frame_idx:06d}.jpg\"), img)\n",
    "            \n",
    "            img_overlay = img.copy()\n",
    "            img_pink_overlay = img.copy()\n",
    "            img_blue_overlay = img.copy()\n",
    "            tracks_only = np.zeros_like(img)\n",
    "            pink_only = np.zeros_like(img)\n",
    "            blue_only = np.zeros_like(img)\n",
    "            \n",
    "            for point_idx in range(len(view_trajectories[frame_idx])):\n",
    "                if view_visibilities[frame_idx, point_idx] < 1:\n",
    "                    continue\n",
    "                \n",
    "                current_pos = view_trajectories[frame_idx, point_idx]\n",
    "                if np.isnan(current_pos[0]) or np.isnan(current_pos[1]):\n",
    "                    continue\n",
    "                \n",
    "                current_x, current_y = int(round(current_pos[0])), int(round(current_pos[1]))\n",
    "                \n",
    "                actual_point_idx = selected_points[point_idx] if point_idx < len(selected_points) else point_idx\n",
    "                color_type = point_colors[actual_point_idx % len(point_colors)]\n",
    "                \n",
    "                # start_frame = max(0, frame_idx - fade_frames)\n",
    "                # for hist_frame in range(start_frame, frame_idx):\n",
    "                #     if (view_visibilities[hist_frame, point_idx] < 1 or \n",
    "                #         view_visibilities[hist_frame + 1, point_idx] < 1):\n",
    "                #         continue\n",
    "                    \n",
    "                #     fade_idx = frame_idx - hist_frame - 1\n",
    "                #     if fade_idx >= fade_frames:\n",
    "                #         continue\n",
    "                    \n",
    "                #     # Get pre-computed color\n",
    "                #     if color_type == 'pink':\n",
    "                #         line_color = pink_gradients[fade_idx]\n",
    "                #     else:\n",
    "                #         line_color = blue_gradients[fade_idx]\n",
    "                    \n",
    "                #     # Get positions\n",
    "                #     hist_pos = view_trajectories[hist_frame, point_idx]\n",
    "                #     next_pos = view_trajectories[hist_frame + 1, point_idx]\n",
    "                    \n",
    "                #     if (not np.isnan(hist_pos[0]) and not np.isnan(hist_pos[1]) and \n",
    "                #         not np.isnan(next_pos[0]) and not np.isnan(next_pos[1])):\n",
    "                        \n",
    "                #         hist_x, hist_y = int(round(hist_pos[0])), int(round(hist_pos[1]))\n",
    "                #         next_x, next_y = int(round(next_pos[0])), int(round(next_pos[1]))\n",
    "                        \n",
    "                #         # Draw lines on appropriate images\n",
    "                #         # For overlay images with opacity\n",
    "                #         overlay_temp = img_overlay.copy()\n",
    "                #         cv2.line(overlay_temp, (hist_x, hist_y), (next_x, next_y), line_color, 1)\n",
    "                #         cv2.addWeighted(overlay_temp, 0.5, img_overlay, 0.5, 0, img_overlay)\n",
    "\n",
    "                #         if color_type == 'pink':\n",
    "                #             overlay_temp = img_pink_overlay.copy()\n",
    "                #             cv2.line(overlay_temp, (hist_x, hist_y), (next_x, next_y), line_color, 1)\n",
    "                #             cv2.addWeighted(overlay_temp, 0.5, img_pink_overlay, 0.5, 0, img_pink_overlay)\n",
    "                #             cv2.line(pink_only, (hist_x, hist_y), (next_x, next_y), line_color, 1)\n",
    "                #         else:\n",
    "                #             overlay_temp = img_blue_overlay.copy()\n",
    "                #             cv2.line(overlay_temp, (hist_x, hist_y), (next_x, next_y), line_color, 1)\n",
    "                #             cv2.addWeighted(overlay_temp, 0.5, img_blue_overlay, 0.5, 0, img_blue_overlay)\n",
    "                #             cv2.line(blue_only, (hist_x, hist_y), (next_x, next_y), line_color, 1)\n",
    "                \n",
    "                point_color = pink if color_type == 'pink' else blue\n",
    "                cv2.circle(img_overlay, (current_x, current_y), 1, point_color, -1)\n",
    "                cv2.circle(tracks_only, (current_x, current_y), 1, point_color, -1)\n",
    "                \n",
    "                if color_type == 'pink':\n",
    "                    cv2.circle(img_pink_overlay, (current_x, current_y), 1, point_color, -1)\n",
    "                    cv2.circle(pink_only, (current_x, current_y), 1, point_color, -1)\n",
    "                else:\n",
    "                    cv2.circle(img_blue_overlay, (current_x, current_y), 1, point_color, -1)\n",
    "                    cv2.circle(blue_only, (current_x, current_y), 1, point_color, -1)\n",
    "            \n",
    "            # Save all frame types\n",
    "            cv2.imwrite(os.path.join(temp_dir_overlay, f\"frame_{frame_idx:06d}.jpg\"), img_overlay)\n",
    "            cv2.imwrite(os.path.join(temp_dir_pink_overlay, f\"frame_{frame_idx:06d}.jpg\"), img_pink_overlay)\n",
    "            cv2.imwrite(os.path.join(temp_dir_blue_overlay, f\"frame_{frame_idx:06d}.jpg\"), img_blue_overlay)\n",
    "            cv2.imwrite(os.path.join(temp_dir_tracks_only, f\"frame_{frame_idx:06d}.jpg\"), tracks_only)\n",
    "            cv2.imwrite(os.path.join(temp_dir_pink_only, f\"frame_{frame_idx:06d}.jpg\"), pink_only)\n",
    "            cv2.imwrite(os.path.join(temp_dir_blue_only, f\"frame_{frame_idx:06d}.jpg\"), blue_only)\n",
    "        \n",
    "        video_commands = [\n",
    "            (['ffmpeg', '-framerate', '30', '-i', os.path.join(temp_dir_original, 'frame_%06d.jpg'),\n",
    "              '-c:v', 'libx264', '-pix_fmt', 'yuv420p', os.path.join(output_dir, f\"view{view}.mp4\"), '-y'], \"original\"),\n",
    "            \n",
    "            (['ffmpeg', '-framerate', '30', '-i', os.path.join(temp_dir_overlay, 'frame_%06d.jpg'),\n",
    "              '-c:v', 'libx264', '-pix_fmt', 'yuv420p', os.path.join(output_dir, f\"view{view}_with_tracks.mp4\"), '-y'], \"with tracks\"),\n",
    "            \n",
    "            (['ffmpeg', '-framerate', '30', '-i', os.path.join(temp_dir_pink_overlay, 'frame_%06d.jpg'),\n",
    "              '-c:v', 'libx264', '-pix_fmt', 'yuv420p', os.path.join(output_dir, f\"view{view}_pink_overlay.mp4\"), '-y'], \"pink overlay\"),\n",
    "            \n",
    "            (['ffmpeg', '-framerate', '30', '-i', os.path.join(temp_dir_blue_overlay, 'frame_%06d.jpg'),\n",
    "              '-c:v', 'libx264', '-pix_fmt', 'yuv420p', os.path.join(output_dir, f\"view{view}_blue_overlay.mp4\"), '-y'], \"blue overlay\"),\n",
    "            \n",
    "            (['ffmpeg', '-framerate', '30', '-i', os.path.join(temp_dir_tracks_only, 'frame_%06d.jpg'),\n",
    "              '-c:v', 'libx264', '-pix_fmt', 'yuv420p', os.path.join(output_dir, f\"tracks{view}.mp4\"), '-y'], \"tracks only\"),\n",
    "            \n",
    "            (['ffmpeg', '-framerate', '30', '-i', os.path.join(temp_dir_pink_only, 'frame_%06d.jpg'),\n",
    "              '-c:v', 'libx264', '-pix_fmt', 'yuv420p', os.path.join(output_dir, f\"pink_tracks{view}.mp4\"), '-y'], \"pink tracks only\"),\n",
    "            \n",
    "            (['ffmpeg', '-framerate', '30', '-i', os.path.join(temp_dir_blue_only, 'frame_%06d.jpg'),\n",
    "              '-c:v', 'libx264', '-pix_fmt', 'yuv420p', os.path.join(output_dir, f\"blue_tracks{view}.mp4\"), '-y'], \"blue tracks only\")\n",
    "        ]\n",
    "        \n",
    "        import concurrent.futures\n",
    "        def run_ffmpeg(cmd_name):\n",
    "            cmd, name = cmd_name\n",
    "            result = subprocess.run(cmd, capture_output=True, text=True)\n",
    "            if result.returncode == 0:\n",
    "                return f\"{name} video created\"\n",
    "            else:\n",
    "                return f\"Failed to create {name} video\"\n",
    "        \n",
    "        with concurrent.futures.ThreadPoolExecutor() as executor:\n",
    "            results = list(executor.map(run_ffmpeg, video_commands))\n",
    "            for result in results:\n",
    "                print(result)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# colored"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### save as gifs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import subprocess\n",
    "\n",
    "folder_path = f\"examples_visualization/{scene}/example{i}\"  # Change this to your folder\n",
    "\n",
    "for file in os.listdir(folder_path):\n",
    "    if file.endswith(\".mp4\"):\n",
    "        mp4_path = os.path.join(folder_path, file)\n",
    "        gif_path = os.path.join(folder_path, f\"{os.path.splitext(file)[0]}.gif\")\n",
    "        \n",
    "        cmd = [\n",
    "            'ffmpeg',\n",
    "            '-i', mp4_path,\n",
    "            '-vf', 'fps=30,scale=640:-1:flags=lanczos',\n",
    "            '-c:v', 'gif',\n",
    "            gif_path,\n",
    "            '-y'\n",
    "        ]\n",
    "        \n",
    "        result = subprocess.run(cmd, capture_output=True, text=True)\n",
    "        if result.returncode == 0:\n",
    "            print(f\"✓ Converted {file} to GIF\")\n",
    "        else:\n",
    "            print(f\"✗ Failed to convert {file}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### save tracks in structure compatible with trajan"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "\n",
    "output_dir = f\"/restricted/projectnb/cs599dg/mwakeham/trajectory_examples/{scene}\"\n",
    "os.makedirs(output_dir, exist_ok=True)\n",
    "\n",
    "for idx, example in enumerate(all_examples, start=1):\n",
    "    example_dir = os.path.join(output_dir, f\"example{idx}\")\n",
    "    os.makedirs(example_dir, exist_ok=True)\n",
    "    \n",
    "    traj_pixel = example['trajectories_pixel']\n",
    "    selected_views = example['views']\n",
    "    \n",
    "    visible = (traj_pixel.sum(axis=-1, keepdims=True) != 0).astype(np.float32)\n",
    "    \n",
    "    for v_idx, view in enumerate(selected_views):\n",
    "        view_traj = traj_pixel[v_idx]\n",
    "        view_vis  = visible[v_idx]\n",
    "        \n",
    "        np.save(os.path.join(example_dir, f\"tracks_view{v_idx}.npy\"), view_traj)\n",
    "        np.save(os.path.join(example_dir, f\"visible_view{v_idx}.npy\"), view_vis)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
